{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Email Sentiment Analysis for Software Products\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "- Our organization specializes in various software products. \n",
    "- These products include CRM, ERP, Appointment Booking Software, and more.\n",
    "- Our task is to develop a machine learning model.\n",
    "- The goal is to analyze sentiments in customer emails.\n",
    "\n",
    "\n",
    "**The Problem Statement:**\n",
    "\n",
    "Our executive team has specific objectives:\n",
    "\n",
    "- Understand Sentiments: We need to determine sentiments in each email.\n",
    "- Sentiments could be anger, happiness, or requests for assistance.\n",
    "\n",
    "**Why Sentiment Analysis?**\n",
    "\n",
    "Understanding email sentiment is crucial because:\n",
    "\n",
    "- It enhances customer satisfaction.\n",
    "- It helps improve product quality.\n",
    "- It ensures timely support.\n",
    "- Automating sentiment analysis streamlines customer support processes.\n",
    "- It identifies areas for product improvement.\n",
    "- It promptly addresses customer concerns.\n",
    "\n",
    "This notebook will guide us through:\n",
    "\n",
    "- Data preprocessing.\n",
    "- Sentiment analysis for each email.\n",
    "- Leveraging machine learning and natural language processing.\n",
    "- Better serving our customers and optimizing our software products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary libraries & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sbKCxhrCgm_w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the path to email dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDGGkYCRPV3C",
    "outputId": "0a33c022-bb0e-490e-bda9-1224b763c3a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-219/Desktop/product_and_sentiment_classification_poc/data/prod_email.csv\n"
     ]
    }
   ],
   "source": [
    "path_to_email_data = os.path.join(os.path.dirname(os.getcwd()), 'data', 'prod_email.csv')\n",
    "print(path_to_email_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the email dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "D76xhnrDPqQ8",
    "outputId": "8c068231-c5ca-4f94-d8c4-ec1b2862b66a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket Type</th>\n",
       "      <th>Ticket Subject</th>\n",
       "      <th>Ticket Description</th>\n",
       "      <th>new_product_name</th>\n",
       "      <th>new_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Software bug</td>\n",
       "      <td>Subject: Urgent Assistance Required: Issue wit...</td>\n",
       "      <td>SAP ERP</td>\n",
       "      <td>ERP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Software bug</td>\n",
       "      <td>Subject: Urgent Assistance Required for SAP ER...</td>\n",
       "      <td>SAP ERP</td>\n",
       "      <td>ERP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Software bug</td>\n",
       "      <td>Subject: Frustration with SAP ERP Technical Is...</td>\n",
       "      <td>SAP ERP</td>\n",
       "      <td>ERP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Software bug</td>\n",
       "      <td>Subject: Urgent Assistance Required: Software ...</td>\n",
       "      <td>SAP ERP</td>\n",
       "      <td>ERP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Software bug</td>\n",
       "      <td>Subject: Urgent: Glitch in SAP ERP Software\\nD...</td>\n",
       "      <td>SAP ERP</td>\n",
       "      <td>ERP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ticket Type Ticket Subject  \\\n",
       "0  Technical issue   Software bug   \n",
       "1  Technical issue   Software bug   \n",
       "2  Technical issue   Software bug   \n",
       "3  Technical issue   Software bug   \n",
       "4  Technical issue   Software bug   \n",
       "\n",
       "                                  Ticket Description new_product_name  \\\n",
       "0  Subject: Urgent Assistance Required: Issue wit...          SAP ERP   \n",
       "1  Subject: Urgent Assistance Required for SAP ER...          SAP ERP   \n",
       "2  Subject: Frustration with SAP ERP Technical Is...          SAP ERP   \n",
       "3  Subject: Urgent Assistance Required: Software ...          SAP ERP   \n",
       "4  Subject: Urgent: Glitch in SAP ERP Software\\nD...          SAP ERP   \n",
       "\n",
       "  new_product_type  \n",
       "0              ERP  \n",
       "1              ERP  \n",
       "2              ERP  \n",
       "3              ERP  \n",
       "4              ERP  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_email_data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the distribution Of Various Ticket Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orApnodlPyJR",
    "outputId": "f90ba38d-bda2-433f-91a3-f428eb51588f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product inquiry    199\n",
       "Joyful Shoutout    133\n",
       "Technical issue    118\n",
       "Name: Ticket Type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ticket Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redefining Sentiment Targets\n",
    "\n",
    "In our sentiment analysis task for customer email messages, we are introducing new target categories to enhance our understanding of customer sentiments:\n",
    "\n",
    "- **Angry Email**: This category encompasses emails expressing extreme frustration, disappointment, or dissatisfaction with our products or services. These emails often convey negative sentiments and complaints.\n",
    "\n",
    "- **Happy Email**: Emails falling into this category reflect a positive sentiment. They express satisfaction, gratitude, or appreciation for our products, services, or recent developments. These emails carry a positive tone and may include expressions of thanks.\n",
    "\n",
    "- **Help Email**: The 'Help Email' category covers messages where customers seek assistance, guidance, or support. These emails indicate that customers are facing challenges or need help with specific issues related to our offerings.\n",
    "\n",
    "By redefining our target categories, we aim to more accurately classify the sentiments expressed in customer emails. This approach enables us to better understand and respond to their needs and emotions, ultimately leading to more targeted and effective customer support and engagement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iENP9IFIQp3y"
   },
   "outputs": [],
   "source": [
    "target_map = {\"Technical issue\": \"Angry Email\",\n",
    "              \"Joyful Shoutout\": \"Happy Email\",\n",
    "              \"Product inquiry\": \"Help Email\"\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "36PtGL2CQJ_f"
   },
   "outputs": [],
   "source": [
    "df['target'] = df['Ticket Type'].map(target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the distribution of target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_graph(data, x_col, y_col, title, palette='viridis'):\n",
    "    \"\"\"\n",
    "    Plot a bar graph using Seaborn.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): The DataFrame containing the data.\n",
    "        x_col (str): The name of the column for the x-axis.\n",
    "        y_col (str): The name of the column for the y-axis.\n",
    "        title (str): The title of the plot.\n",
    "        palette (str, optional): The color palette to use. Default is 'viridis'.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=x_col, y=y_col, data=data, palette=palette)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAIjCAYAAAAJLyrXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABEO0lEQVR4nO3deXxN1/7/8fdJIhGRhIRMFYIaa54pFaUihlbLbakSNVaDkvZbza/mW01VBVXlttdQt6bqLb2l5ZpKS4y9uFql8qXaEpQSMUSG/fujD+frSEJWiJPE6/l47Mcje6211/7scE7yzh6OzbIsSwAAAACAXHNxdgEAAAAAUNgQpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpACgEOrbt6/CwsKMt7PZbBo6dOjdLwhasGCBbDabjh07lu/7uvnf/9ixY7LZbHrnnXfyfd+SNH78eNlstnuyLwAoqAhSAFBA2Gy2XC1ff/21s0uVJH355ZcaP378bcddDxi3W/ISDPPL119/7VCbh4eHAgMDFR4erjfffFNnzpy5K/u5fPmyxo8fX2D+TW9UkGsDgILAzdkFAAD+9I9//MNhfeHChVq3bl2W9ho1aujDDz9UZmbmvSwviy+//FKzZs26bZh65JFHshzDgAED1KRJEw0aNMjeVrJkyfwo844MHz5cjRs3VkZGhs6cOaNt27Zp3Lhxio+P1yeffKJHH33UPrZ3797q0aOHPDw8cj3/5cuXNWHCBElSeHh4rre7F//+t6pt9OjReu211/J1/wBQ0BGkAKCAeO655xzWt2/frnXr1mVpL2wqVaqkSpUqObS98MILqlSpUoE/tlatWql79+4Obfv27VP79u3VrVs3/fDDDwoODpYkubq6ytXVNV/ruXTpkry8vFSsWLF83c/tuLm5yc2NXyEA3N+4tA8ACqHs7pHKzMzUjBkzVLt2bRUvXlxly5ZVhw4dtHv37lvO9cYbb8jFxUUzZ860t3311Vdq1aqVvLy85O3trU6dOun777932P+sWbMkOV6SmBcpKSny8vLSSy+9lKXv119/laurq+Li4iT932WCW7Zs0eDBg+Xv7y8fHx/16dNHf/zxR5btb3cceVG3bl1Nnz5d58+f13vvvWdvz+4eqd27dysiIkJlypSRp6enKlasqH79+kn6876msmXLSpImTJhg/x5eP8PXt29flSxZUomJierYsaO8vb3Vq1cve19Ol0JOmzZNFSpUkKenp1q3bq0DBw449IeHh2d79uvGOW9XW3b3SKWnp+uvf/2rKleuLA8PD4WFhen//b//p9TUVIdxYWFh6ty5s7799ls1adJExYsXV6VKlbRw4cLsv+EAUEARpACgiOjfv79GjBih0NBQTZ48Wa+99pqKFy+u7du357jN6NGjNXbsWP3tb3/TsGHDJP15iWGnTp1UsmRJTZ48WWPGjNEPP/ygli1b2kPC4MGD9dhjj9nHX1/yomTJknryySe1bNkyZWRkOPQtWbJElmXZA8R1Q4cO1cGDBzV+/Hj16dNHixYtUteuXWVZln1Mbo4jr7p37y5PT0/9+9//znHM6dOn1b59ex07dkyvvfaaZs6cqV69etn/PcqWLavZs2dLkp588kn79/Cpp56yz5Genq6IiAgFBATonXfeUbdu3W5Z18KFC/Xuu+8qOjpasbGxOnDggB599FGdOnXK6PhyU9vNBgwYoLFjx6pBgwaaNm2aWrdurbi4OPXo0SPL2CNHjqh79+567LHHNHXqVJUuXVp9+/a945ALAPeUBQAokKKjo62c3qajoqKsChUq2Nc3btxoSbKGDx+eZWxmZqb9a0lWdHS0ZVmW9fLLL1suLi7WggUL7P0XL160SpUqZQ0cONBhjqSkJMvX19eh/Vb13Y6Xl5cVFRVlX1+7dq0lyfrqq68cxtWpU8dq3bq1fX3+/PmWJKthw4bWtWvX7O1vv/22Jcn6/PPPjY8jO5s2bbIkWcuXL89xTN26da3SpUtnqe3o0aOWZVnWihUrLEnWrl27cpzjzJkzliRr3LhxWfqioqIsSdZrr72Wbd+N//5Hjx61JFmenp7Wr7/+am/fsWOHJckaOXKkva1169YO39Oc5rxVbePGjXP4t9+7d68lyRowYIDDuFdeecWSZG3cuNHeVqFCBUuStWXLFnvb6dOnLQ8PD+vll1/Osi8AKKg4IwUARcA///lP2Ww2jRs3LkvfzZdgWZaloUOHasaMGfr4448VFRVl71u3bp3Onz+vnj176vfff7cvrq6uatq0qTZt2pQv9bdr104hISFatGiRve3AgQPav39/tvdRDRo0yOE+oSFDhsjNzU1ffvnlPTuOkiVL6uLFizn2lypVSpK0atUqpaWl5Xk/Q4YMyfXYrl276oEHHrCvN2nSRE2bNrV/X/LL9fljYmIc2l9++WVJ0urVqx3aa9asqVatWtnXy5Ytq2rVqul///d/87VOALibuFMUAIqAxMREhYSEyM/P77ZjFy5cqJSUFM2ePVs9e/Z06Pvpp58kyeFpdDfy8fG582Kz4eLiol69emn27Nm6fPmySpQooUWLFql48eL6y1/+kmV8lSpVHNZLliyp4OBg+yV79+I4UlJS5O3tnWN/69at1a1bN02YMEHTpk1TeHi4unbtqmeffTbXT/Zzc3NTuXLlcl3Tzd8XSapatao++eSTXM+RFz///LNcXFz04IMPOrQHBQWpVKlS+vnnnx3ay5cvn2WO0qVLZ3ufGwAUVAQpALjPPPzww9q7d6/ee+89Pf300w7h6/ojtf/xj38oKCgoy7b5+aS2Pn36aMqUKVq5cqV69uypxYsXq3PnzvL19TWeK7+PIy0tTYcPH1atWrVyHGOz2fTpp59q+/bt+uKLL7R27Vr169dPU6dO1fbt23P1uHcPDw+5uNzdi0dsNpvDvWTX3Xx/Wl7nzo2cnm6YXV0AUFARpACgCKhcubLWrl2rc+fO3fas1IMPPqi3335b4eHh6tChgzZs2GA/s1K5cmVJUkBAgNq1a3fLefL6lL6c1KpVS/Xr19eiRYtUrlw5HT9+3OFJgjf66aef1KZNG/t6SkqKTp48qY4dO0oyO468+PTTT3XlyhVFRETcdmyzZs3UrFkzTZo0SYsXL1avXr20dOlSDRgw4K5/D6+fibvR4cOHHZ7wV7p06Wwvobv5rJFJbRUqVFBmZqZ++ukn1ahRw95+6tQpnT9/XhUqVMj1XABQWHCPFAAUAd26dZNlWfYPUL1Rdn/lr1Onjr788ksdPHhQXbp00ZUrVyRJERER8vHx0ZtvvpntfT1nzpyxf+3l5SVJOn/+/F06ij8/1Pbf//63pk+fLn9/f0VGRmY77oMPPnCob/bs2UpPT7ePNzkOU/v27dOIESNUunRpRUdH5zjujz/+yPK9r1evniTZHwleokQJSXfve7hy5Ur99ttv9vWdO3dqx44dDt/HypUr68cff3T4Huzbt09bt251mMuktusBdvr06Q7t8fHxkqROnToZHQcAFAackQKAIqBNmzbq3bu33n33Xf3000/q0KGDMjMz9c0336hNmzYaOnRolm2aNWumzz//XB07dlT37t21cuVK+fj4aPbs2erdu7caNGigHj16qGzZsjp+/LhWr16thx9+2P7ZSQ0bNpQkDR8+XBEREXJ1dc32Udcmnn32Wb366qtasWKFhgwZkuMHz167dk1t27bV008/rUOHDun9999Xy5Yt9fjjj0uS0XHcyjfffKOrV68qIyNDZ8+e1datW/Wvf/1Lvr6+WrFiRbaXDV730Ucf6f3339eTTz6pypUr6+LFi/rwww/l4+NjDx6enp6qWbOmli1bpqpVq8rPz0+1atW65SWDt/Lggw+qZcuWGjJkiFJTU+2B9NVXX7WP6devn+Lj4xUREaH+/fvr9OnTmjNnjh566CElJyfbx5nUVrduXUVFRemDDz7Q+fPn1bp1a+3cuVMfffSRunbt6nD2EACKDGc+MhAAkDOTx59blmWlp6dbU6ZMsapXr265u7tbZcuWtSIjI609e/bYx+iGx59f9/nnn1tubm7WM888Y2VkZFiW9efjvyMiIixfX1+rePHiVuXKla2+fftau3fvdtjfsGHDrLJly1o2m83oUeg3P/78Rh07drQkWdu2bcvSd/0R45s3b7YGDRpklS5d2ipZsqTVq1cv6+zZs1nG5+Y4snP98efXl2LFillly5a1HnnkEWvSpEnW6dOnc6zt+uPPv/vuO6tnz55W+fLlLQ8PDysgIMDq3Llzln1v27bNatiwoeXu7u7wuPGoqCjLy8sr2/pyevz5lClTrKlTp1qhoaGWh4eH1apVK2vfvn1Ztv/444+tSpUqWe7u7la9evWstWvXZvt/Kqfabn78uWVZVlpamjVhwgSrYsWKVrFixazQ0FArNjbWunr1qsO4ChUqWJ06dcpSU06PZQeAgspmWdzZCQAoOJ588kn997//1ZEjR7L0LViwQM8//7x27dqlRo0aOaE6AAD+xD1SAIAC4+TJk1q9erV69+7t7FIAALgl7pECADjd0aNHtXXrVv39739XsWLFNHjwYGeXBADALXFGCgDgdJs3b1bv3r119OhRffTRR7d8iAMAAAUB90gBAAAAgCHOSAEAAACAIYIUAAAAABjiYROSMjMzdeLECXl7e8tmszm7HAAAAABOYlmWLl68qJCQELm45HzeiSAl6cSJEwoNDXV2GQAAAAAKiF9++UXlypXLsZ8gJcnb21vSn98sHx8fJ1cDAAAAwFmSk5MVGhpqzwg5IUhJ9sv5fHx8CFIAAAAAbnvLDw+bAAAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDTg1ScXFxaty4sby9vRUQEKCuXbvq0KFDDmOuXr2q6Oho+fv7q2TJkurWrZtOnTrlMOb48ePq1KmTSpQooYCAAP3P//yP0tPT7+WhAAAAALiPODVIbd68WdHR0dq+fbvWrVuntLQ0tW/fXpcuXbKPGTlypL744gstX75cmzdv1okTJ/TUU0/Z+zMyMtSpUyddu3ZN27Zt00cffaQFCxZo7NixzjgkAAAAAPcBm2VZlrOLuO7MmTMKCAjQ5s2b9cgjj+jChQsqW7asFi9erO7du0uSfvzxR9WoUUMJCQlq1qyZvvrqK3Xu3FknTpxQYGCgJGnOnDkaNWqUzpw5I3d399vuNzk5Wb6+vrpw4YJ8fHzy9RgBAAAAFFy5zQYF6h6pCxcuSJL8/PwkSXv27FFaWpratWtnH1O9enWVL19eCQkJkqSEhATVrl3bHqIkKSIiQsnJyfr++++z3U9qaqqSk5MdFgAAAADIrQITpDIzMzVixAg9/PDDqlWrliQpKSlJ7u7uKlWqlMPYwMBAJSUl2cfcGKKu91/vy05cXJx8fX3tS2ho6F0+GgAAAABFWYEJUtHR0Tpw4ICWLl2a7/uKjY3VhQsX7Msvv/yS7/sEAAAAUHS4ObsASRo6dKhWrVqlLVu2qFy5cvb2oKAgXbt2TefPn3c4K3Xq1CkFBQXZx+zcudNhvutP9bs+5mYeHh7y8PC4y0dxe+2fmXjP9wkUBf9exsNjAABAweLUM1KWZWno0KFasWKFNm7cqIoVKzr0N2zYUMWKFdOGDRvsbYcOHdLx48fVvHlzSVLz5s313//+V6dPn7aPWbdunXx8fFSzZs17cyAAAAAA7itOPSMVHR2txYsX6/PPP5e3t7f9niZfX195enrK19dX/fv3V0xMjPz8/OTj46Nhw4apefPmatasmSSpffv2qlmzpnr37q23335bSUlJGj16tKKjo51y1gkAAABA0efUIDV79mxJUnh4uEP7/Pnz1bdvX0nStGnT5OLiom7duik1NVURERF6//337WNdXV21atUqDRkyRM2bN5eXl5eioqI0cSKX0QEAAADIHwXqc6Sc5V59jhT3SAF5wz1SAADgXimUnyMFAAAAAIUBQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADDk1SG3ZskVdunRRSEiIbDabVq5c6dBvs9myXaZMmWIfExYWlqX/rbfeusdHAgAAAOB+4tQgdenSJdWtW1ezZs3Ktv/kyZMOy7x582Sz2dStWzeHcRMnTnQYN2zYsHtRPgAAAID7lJszdx4ZGanIyMgc+4OCghzWP//8c7Vp00aVKlVyaPf29s4yFgAAAADyS6G5R+rUqVNavXq1+vfvn6Xvrbfekr+/v+rXr68pU6YoPT39lnOlpqYqOTnZYQEAAACA3HLqGSkTH330kby9vfXUU085tA8fPlwNGjSQn5+ftm3bptjYWJ08eVLx8fE5zhUXF6cJEybkd8kAAAAAiqhCE6TmzZunXr16qXjx4g7tMTEx9q/r1Kkjd3d3DR48WHFxcfLw8Mh2rtjYWIftkpOTFRoamj+FAwAAAChyCkWQ+uabb3To0CEtW7bstmObNm2q9PR0HTt2TNWqVct2jIeHR44hCwAAAABup1DcIzV37lw1bNhQdevWve3YvXv3ysXFRQEBAfegMgAAAAD3I6eekUpJSdGRI0fs60ePHtXevXvl5+en8uXLS/rzsrvly5dr6tSpWbZPSEjQjh071KZNG3l7eyshIUEjR47Uc889p9KlS9+z4wAAAABwf3FqkNq9e7fatGljX79+31JUVJQWLFggSVq6dKksy1LPnj2zbO/h4aGlS5dq/PjxSk1NVcWKFTVy5EiH+58AAAAA4G6zWZZlObsIZ0tOTpavr68uXLggHx+ffNtP+2cm5tvcQFH272VjnV0CAAC4T+Q2GxSKe6QAAAAAoCAhSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIacGqS1btqhLly4KCQmRzWbTypUrHfr79u0rm83msHTo0MFhzLlz59SrVy/5+PioVKlS6t+/v1JSUu7hUQAAAAC43zg1SF26dEl169bVrFmzchzToUMHnTx50r4sWbLEob9Xr176/vvvtW7dOq1atUpbtmzRoEGD8rt0AAAAAPcxN2fuPDIyUpGRkbcc4+HhoaCgoGz7Dh48qDVr1mjXrl1q1KiRJGnmzJnq2LGj3nnnHYWEhNz1mgEAAACgwN8j9fXXXysgIEDVqlXTkCFDdPbsWXtfQkKCSpUqZQ9RktSuXTu5uLhox44dOc6Zmpqq5ORkhwUAAAAAcqtAB6kOHTpo4cKF2rBhgyZPnqzNmzcrMjJSGRkZkqSkpCQFBAQ4bOPm5iY/Pz8lJSXlOG9cXJx8fX3tS2hoaL4eBwAAAICixamX9t1Ojx497F/Xrl1bderUUeXKlfX111+rbdu2eZ43NjZWMTEx9vXk5GTCFAAAAIBcK9BnpG5WqVIllSlTRkeOHJEkBQUF6fTp0w5j0tPTde7cuRzvq5L+vO/Kx8fHYQEAAACA3CpUQerXX3/V2bNnFRwcLElq3ry5zp8/rz179tjHbNy4UZmZmWratKmzygQAAABQxDn10r6UlBT72SVJOnr0qPbu3Ss/Pz/5+flpwoQJ6tatm4KCgpSYmKhXX31VDz74oCIiIiRJNWrUUIcOHTRw4EDNmTNHaWlpGjp0qHr06MET+wAAAADkG6eekdq9e7fq16+v+vXrS5JiYmJUv359jR07Vq6urtq/f78ef/xxVa1aVf3791fDhg31zTffyMPDwz7HokWLVL16dbVt21YdO3ZUy5Yt9cEHHzjrkAAAAADcB5x6Rio8PFyWZeXYv3bt2tvO4efnp8WLF9/NsgAAAADglgrVPVIAAAAAUBAQpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAy5ObsAALjf1HtjvLNLAAqdvaPHO7sEAHDAGSkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDTg1SW7ZsUZcuXRQSEiKbzaaVK1fa+9LS0jRq1CjVrl1bXl5eCgkJUZ8+fXTixAmHOcLCwmSz2RyWt9566x4fCQAAAID7iVOD1KVLl1S3bl3NmjUrS9/ly5f13XffacyYMfruu+/02Wef6dChQ3r88cezjJ04caJOnjxpX4YNG3YvygcAAABwn3Jz5s4jIyMVGRmZbZ+vr6/WrVvn0Pbee++pSZMmOn78uMqXL29v9/b2VlBQUL7WCgAAAADXFap7pC5cuCCbzaZSpUo5tL/11lvy9/dX/fr1NWXKFKWnp99yntTUVCUnJzssAAAAAJBbTj0jZeLq1asaNWqUevbsKR8fH3v78OHD1aBBA/n5+Wnbtm2KjY3VyZMnFR8fn+NccXFxmjBhwr0oGwAAAEARVCiCVFpamp5++mlZlqXZs2c79MXExNi/rlOnjtzd3TV48GDFxcXJw8Mj2/liY2MdtktOTlZoaGj+FA8AAACgyCnwQep6iPr555+1ceNGh7NR2WnatKnS09N17NgxVatWLdsxHh4eOYYsAAAAALidAh2kroeon376SZs2bZK/v/9tt9m7d69cXFwUEBBwDyoEAAAAcD9yapBKSUnRkSNH7OtHjx7V3r175efnp+DgYHXv3l3fffedVq1apYyMDCUlJUmS/Pz85O7uroSEBO3YsUNt2rSRt7e3EhISNHLkSD333HMqXbq0sw4LAAAAQBHn1CC1e/dutWnTxr5+/b6lqKgojR8/Xv/6178kSfXq1XPYbtOmTQoPD5eHh4eWLl2q8ePHKzU1VRUrVtTIkSMd7n8CAAAAgLvNqUEqPDxclmXl2H+rPklq0KCBtm/ffrfLAgAAAIBbKlSfIwUAAAAABQFBCgAAAAAMEaQAAAAAwBBBCgAAAAAMEaQAAAAAwBBBCgAAAAAMEaQAAAAAwBBBCgAAAAAMEaQAAAAAwJCbswsAAAC43wzb8JKzSwAKpZltZzi7BDvOSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAoTwFqUqVKuns2bNZ2s+fP69KlSrdcVEAAAAAUJDlKUgdO3ZMGRkZWdpTU1P122+/3XFRAAAAAFCQuZkM/te//mX/eu3atfL19bWvZ2RkaMOGDQoLC7trxQEAAABAQWQUpLp27SpJstlsioqKcugrVqyYwsLCNHXq1LtWHAAAAAAUREZBKjMzU5JUsWJF7dq1S2XKlMmXogAAAACgIDMKUtcdPXr0btcBAAAAAIVGnoKUJG3YsEEbNmzQ6dOn7Weqrps3b94dFwYAAAAABVWegtSECRM0ceJENWrUSMHBwbLZbHe7LgAAAAAosPIUpObMmaMFCxaod+/ed7seAAAAACjw8vQ5UteuXVOLFi3udi0AAAAAUCjkKUgNGDBAixcvvtu1AAAAAEChkKdL+65evaoPPvhA69evV506dVSsWDGH/vj4+LtSHAAAAAAURHkKUvv371e9evUkSQcOHHDo48ETAAAAAIq6PAWpTZs23e06AAAAAKDQyNM9UgAAAABwP8vTGak2bdrc8hK+jRs35rkgAAAAACjo8hSkrt8fdV1aWpr27t2rAwcOKCoq6m7UBQAAAAAFVp6C1LRp07JtHz9+vFJSUu6oIAAAAAAo6O7qPVLPPfec5s2bdzenBAAAAIAC564GqYSEBBUvXvxuTgkAAAAABU6eLu176qmnHNYty9LJkye1e/dujRkz5q4UBgAAAAAFVZ6ClK+vr8O6i4uLqlWrpokTJ6p9+/Z3pTAAAAAAKKjyFKTmz59/t+sAAAAAgEIjT0Hquj179ujgwYOSpIceekj169e/K0UBAAAAQEGWp4dNnD59Wo8++qgaN26s4cOHa/jw4WrYsKHatm2rM2fO5HqeLVu2qEuXLgoJCZHNZtPKlSsd+i3L0tixYxUcHCxPT0+1a9dOP/30k8OYc+fOqVevXvLx8VGpUqXUv39/HsEOAAAAIF/lKUgNGzZMFy9e1Pfff69z587p3LlzOnDggJKTkzV8+PBcz3Pp0iXVrVtXs2bNyrb/7bff1rvvvqs5c+Zox44d8vLyUkREhK5evWof06tXL33//fdat26dVq1apS1btmjQoEF5OSwAAAAAyJU8Xdq3Zs0arV+/XjVq1LC31axZU7NmzTJ62ERkZKQiIyOz7bMsS9OnT9fo0aP1xBNPSJIWLlyowMBArVy5Uj169NDBgwe1Zs0a7dq1S40aNZIkzZw5Ux07dtQ777yjkJCQvBweAAAAANxSns5IZWZmqlixYlnaixUrpszMzDsuSpKOHj2qpKQktWvXzt7m6+urpk2bKiEhQdKfn1tVqlQpe4iSpHbt2snFxUU7duzIce7U1FQlJyc7LAAAAACQW3kKUo8++qheeuklnThxwt7222+/aeTIkWrbtu1dKSwpKUmSFBgY6NAeGBho70tKSlJAQIBDv5ubm/z8/OxjshMXFydfX1/7EhoaeldqBgAAAHB/yFOQeu+995ScnKywsDBVrlxZlStXVsWKFZWcnKyZM2fe7RrvutjYWF24cMG+/PLLL84uCQAAAEAhkqd7pEJDQ/Xdd99p/fr1+vHHHyVJNWrUcLgM704FBQVJkk6dOqXg4GB7+6lTp1SvXj37mNOnTztsl56ernPnztm3z46Hh4c8PDzuWq0AAAAA7i9GZ6Q2btyomjVrKjk5WTabTY899piGDRumYcOGqXHjxnrooYf0zTff3JXCKlasqKCgIG3YsMHelpycrB07dqh58+aSpObNm+v8+fPas2ePQ42ZmZlq2rTpXakDAAAAAG5mdEZq+vTpGjhwoHx8fLL0+fr6avDgwYqPj1erVq1yNV9KSoqOHDliXz969Kj27t0rPz8/lS9fXiNGjNAbb7yhKlWqqGLFihozZoxCQkLUtWtXSX+eBevQoYMGDhyoOXPmKC0tTUOHDlWPHj14Yh8AAACAfGN0Rmrfvn3q0KFDjv3t27d3ODt0O7t371b9+vVVv359SVJMTIzq16+vsWPHSpJeffVVDRs2TIMGDVLjxo2VkpKiNWvWqHjx4vY5Fi1apOrVq6tt27bq2LGjWrZsqQ8++MDksAAAAADAiNEZqVOnTmX72HP7ZG5uOnPmTK7nCw8Pl2VZOfbbbDZNnDhREydOzHGMn5+fFi9enOt9AgAAAMCdMjoj9cADD+jAgQM59u/fv9/hwRAAAAAAUBQZBamOHTtqzJgxunr1apa+K1euaNy4cercufNdKw4AAAAACiKjS/tGjx6tzz77TFWrVtXQoUNVrVo1SdKPP/6oWbNmKSMjQ6+//nq+FAoAAAAABYVRkAoMDNS2bds0ZMgQxcbG2u9vstlsioiI0KxZsxQYGJgvhQIAAABAQWH8gbwVKlTQl19+qT/++ENHjhyRZVmqUqWKSpcunR/1AQAAAECBYxykritdurQaN258N2sBAAAAgELB6GETAAAAAACCFAAAAAAYI0gBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYKvBBKiwsTDabLcsSHR0tSQoPD8/S98ILLzi5agAAAABFmZuzC7idXbt2KSMjw75+4MABPfbYY/rLX/5ibxs4cKAmTpxoXy9RosQ9rREAAADA/aXAB6myZcs6rL/11luqXLmyWrdubW8rUaKEgoKC7nVpAAAAAO5TBf7Svhtdu3ZNH3/8sfr16yebzWZvX7RokcqUKaNatWopNjZWly9fvuU8qampSk5OdlgAAAAAILcK/BmpG61cuVLnz59X37597W3PPvusKlSooJCQEO3fv1+jRo3SoUOH9Nlnn+U4T1xcnCZMmHAPKgYAAABQFBWqIDV37lxFRkYqJCTE3jZo0CD717Vr11ZwcLDatm2rxMREVa5cOdt5YmNjFRMTY19PTk5WaGho/hUOAAAAoEgpNEHq559/1vr16295pkmSmjZtKkk6cuRIjkHKw8NDHh4ed71GAAAAAPeHQnOP1Pz58xUQEKBOnTrdctzevXslScHBwfegKgAAAAD3o0JxRiozM1Pz589XVFSU3Nz+r+TExEQtXrxYHTt2lL+/v/bv36+RI0fqkUceUZ06dZxYMQAAAICirFAEqfXr1+v48ePq16+fQ7u7u7vWr1+v6dOn69KlSwoNDVW3bt00evRoJ1UKAAAA4H5QKIJU+/btZVlWlvbQ0FBt3rzZCRUBAAAAuJ8VmnukAAAAAKCgIEgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgKECHaTGjx8vm83msFSvXt3ef/XqVUVHR8vf318lS5ZUt27ddOrUKSdWDAAAAOB+UKCDlCQ99NBDOnnypH359ttv7X0jR47UF198oeXLl2vz5s06ceKEnnrqKSdWCwAAAOB+4ObsAm7Hzc1NQUFBWdovXLiguXPnavHixXr00UclSfPnz1eNGjW0fft2NWvW7F6XCgAAAOA+UeDPSP30008KCQlRpUqV1KtXLx0/flyStGfPHqWlpaldu3b2sdWrV1f58uWVkJBwyzlTU1OVnJzssAAAAABAbhXoINW0aVMtWLBAa9as0ezZs3X06FG1atVKFy9eVFJSktzd3VWqVCmHbQIDA5WUlHTLeePi4uTr62tfQkND8/EoAAAAABQ1BfrSvsjISPvXderUUdOmTVWhQgV98skn8vT0zPO8sbGxiomJsa8nJycTpgAAAADkWoE+I3WzUqVKqWrVqjpy5IiCgoJ07do1nT9/3mHMqVOnsr2n6kYeHh7y8fFxWAAAAAAgtwpVkEpJSVFiYqKCg4PVsGFDFStWTBs2bLD3Hzp0SMePH1fz5s2dWCUAAACAoq5AX9r3yiuvqEuXLqpQoYJOnDihcePGydXVVT179pSvr6/69++vmJgY+fn5ycfHR8OGDVPz5s15Yh8AAACAfFWgg9Svv/6qnj176uzZsypbtqxatmyp7du3q2zZspKkadOmycXFRd26dVNqaqoiIiL0/vvvO7lqAAAAAEVdgQ5SS5cuvWV/8eLFNWvWLM2aNeseVQQAAAAAheweKQAAAAAoCAhSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCIIAUAAAAAhgp0kIqLi1Pjxo3l7e2tgIAAde3aVYcOHXIYEx4eLpvN5rC88MILTqoYAAAAwP2gQAepzZs3Kzo6Wtu3b9e6deuUlpam9u3b69KlSw7jBg4cqJMnT9qXt99+20kVAwAAALgfuDm7gFtZs2aNw/qCBQsUEBCgPXv26JFHHrG3lyhRQkFBQbmeNzU1Vampqfb15OTkOy8WAAAAwH2jQJ+RutmFCxckSX5+fg7tixYtUpkyZVSrVi3Fxsbq8uXLt5wnLi5Ovr6+9iU0NDTfagYAAABQ9BToM1I3yszM1IgRI/Twww+rVq1a9vZnn31WFSpUUEhIiPbv369Ro0bp0KFD+uyzz3KcKzY2VjExMfb15ORkwhQAAACAXCs0QSo6OloHDhzQt99+69A+aNAg+9e1a9dWcHCw2rZtq8TERFWuXDnbuTw8POTh4ZGv9QIAAAAougrFpX1Dhw7VqlWrtGnTJpUrV+6WY5s2bSpJOnLkyL0oDQAAAMB9qECfkbIsS8OGDdOKFSv09ddfq2LFirfdZu/evZKk4ODgfK4OAAAAwP2qQAep6OhoLV68WJ9//rm8vb2VlJQkSfL19ZWnp6cSExO1ePFidezYUf7+/tq/f79GjhypRx55RHXq1HFy9QAAAACKqgIdpGbPni3pzw/dvdH8+fPVt29fubu7a/369Zo+fbouXbqk0NBQdevWTaNHj3ZCtQAAAADuFwU6SFmWdcv+0NBQbd68+R5VAwAAAAB/KhQPmwAAAACAgoQgBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGikyQmjVrlsLCwlS8eHE1bdpUO3fudHZJAAAAAIqoIhGkli1bppiYGI0bN07fffed6tatq4iICJ0+fdrZpQEAAAAogopEkIqPj9fAgQP1/PPPq2bNmpozZ45KlCihefPmObs0AAAAAEWQm7MLuFPXrl3Tnj17FBsba29zcXFRu3btlJCQkO02qampSk1Nta9fuHBBkpScnJyvtaanXc3X+YGiKr9fm/daxtXU2w8C4KCovQ9cu8T7AJAX9+K94Po+LMu65bhCH6R+//13ZWRkKDAw0KE9MDBQP/74Y7bbxMXFacKECVnaQ0ND86VGAHfGd0Wcs0sA4GS+k95ydgkACoAP9Ld7tq+LFy/K19c3x/5CH6TyIjY2VjExMfb1zMxMnTt3Tv7+/rLZbE6sDM6SnJys0NBQ/fLLL/Lx8XF2OQCcgPcBALwPQPrzTNTFixcVEhJyy3GFPkiVKVNGrq6uOnXqlEP7qVOnFBQUlO02Hh4e8vDwcGgrVapUfpWIQsTHx4c3TuA+x/sAAN4HcKszUdcV+odNuLu7q2HDhtqwYYO9LTMzUxs2bFDz5s2dWBkAAACAoqrQn5GSpJiYGEVFRalRo0Zq0qSJpk+frkuXLun55593dmkAAAAAiqAiEaSeeeYZnTlzRmPHjlVSUpLq1aunNWvWZHkABZATDw8PjRs3LsslnwDuH7wPAOB9ACZs1u2e6wcAAAAAcFDo75ECAAAAgHuNIAUAAAAAhghSAAAAAGCIIIUiISwsTNOnT3d2GXl2c/02m00rV650Wj0ACo7x48erXr169vW+ffuqa9euTqsHwL2zYMECh886vfn9AM5FkILT5PTLwNdffy2bzabz58/f83psNluWpUOHDvm+7127dmnQoEH5vh/AGQraaz0vrtea3ZKUlJSv+37llVccPisRKAoSEhLk6uqqTp06ObuU2zp27FiOr//t27fn676feeYZHT58OF/3gbwrEo8/B+6WDh06aP78+Q5t9+IRqGXLls33fQC4c4cOHZKPj49DW0BAQL7us2TJkipZsmS+7gO41+bOnathw4Zp7ty5OnHihEJCQvJ9n9euXZO7u3uet1+/fr0eeughhzZ/f/87LeuWPD095enpma/7QN5xRgqFwrfffqtWrVrJ09NToaGhGj58uC5dupTjeJvNptmzZysyMlKenp6qVKmSPv3009vux8PDQ0FBQQ5L6dKlHeb929/+ps6dO6tEiRKqUaOGEhISdOTIEYWHh8vLy0stWrRQYmKifZvExEQ98cQTCgwMVMmSJdW4cWOtX7/eYb+F/dJE4G44e/asevbsqQceeEAlSpRQ7dq1tWTJEocx4eHhGjp0qIYOHSpfX1+VKVNGY8aM0Y2f5BEWFqa//vWv6tmzp7y8vPTAAw9o1qxZ9v5+/fqpc+fODvOmpaUpICBAc+fOvWWNAQEBWd4jXFz+/FF6/czbm2++qcDAQJUqVUoTJ05Uenq6/ud//kd+fn4qV65clj/WjBo1SlWrVlWJEiVUqVIljRkzRmlpafZ+LuVBUZOSkqJly5ZpyJAh6tSpkxYsWODQf/0M8IYNG9SoUSOVKFFCLVq00KFDhxzGvfHGGwoICJC3t7cGDBig1157LdvLYCdNmqSQkBBVq1ZNEydOVK1atbLUVK9ePY0ZM+aWdfv7+2d5/RcrVkzS/71O582bp/Lly6tkyZJ68cUXlZGRobfffltBQUEKCAjQpEmTHOaMj49X7dq15eXlpdDQUL344otKSUmx9998aR8KFoIUCrzExER16NBB3bp10/79+7Vs2TJ9++23Gjp06C23GzNmjLp166Z9+/apV69e6tGjhw4ePHjH9fz1r39Vnz59tHfvXlWvXl3PPvusBg8erNjYWO3evVuWZTnUlpKSoo4dO2rDhg36z3/+ow4dOqhLly46fvz4HdcCFCVXr15Vw4YNtXr1ah04cECDBg1S7969tXPnTodxH330kdzc3LRz507NmDFD8fHx+vvf/+4wZsqUKapbt67+85//6LXXXtNLL72kdevWSZIGDBigNWvW6OTJk/bxq1at0uXLl/XMM8/c0TFs3LhRJ06c0JYtWxQfH69x48apc+fOKl26tHbs2KEXXnhBgwcP1q+//mrfxtvbWwsWLNAPP/ygGTNm6MMPP9S0adPuqA6gIPvkk09UvXp1VatWTc8995zmzZun7D7W9PXXX9fUqVO1e/duubm5qV+/fva+RYsWadKkSZo8ebL27Nmj8uXLa/bs2Vnm2LBhgw4dOqR169Zp1apV6tevnw4ePKhdu3bZx/znP//R/v379fzzz9/RcSUmJuqrr77SmjVrtGTJEs2dO1edOnXSr7/+qs2bN2vy5MkaPXq0duzYYd/GxcVF7777rr7//nt99NFH2rhxo1599dU7qgP3kAU4SVRUlOXq6mp5eXk5LMWLF7ckWX/88YdlWZbVv39/a9CgQQ7bfvPNN5aLi4t15coVy7Isq0KFCta0adPs/ZKsF154wWGbpk2bWkOGDDGuZ9KkSQ7zjh492r6ekJBgSbLmzp1rb1uyZIlVvHjxWx77Qw89ZM2cOdO+nl39K1asuOUcQGGR29d6djp16mS9/PLL9vXWrVtbNWrUsDIzM+1to0aNsmrUqGFfr1ChgtWhQweHeZ555hkrMjLSvl6zZk1r8uTJ9vUuXbpYffv2zbGOTZs2WZKyHEPNmjUdjrNChQpWRkaGva1atWpWq1at7Ovp6emWl5eXtWTJkhz3NWXKFKthw4b29XHjxll169Z12M8TTzyR4/ZAQdeiRQtr+vTplmVZVlpamlWmTBlr06ZN9v7rr7f169fb21avXm1Jsv/cb9q0qRUdHe0w78MPP5zltRIYGGilpqY6jIuMjHT4fWDYsGFWeHh4jvUePXrUkmR5enpmeQ+4bty4cVaJEiWs5ORke1tERIQVFhaW5T0hLi4ux30tX77c8vf3t6/Pnz/f8vX1ddjPjccI5+IeKThVmzZtsvwFaceOHXruuefs6/v27dP+/fu1aNEie5tlWcrMzNTRo0dVo0aNbOdu3rx5lvW9e/ca1+Pn5+ewXqdOHfvXgYGBkqTatWs7tF29elXJycny8fFRSkqKxo8fr9WrV+vkyZNKT0/XlStXOCOF+0puXusZGRl688039cknn+i3337TtWvXlJqaqhIlSjhs16xZM9lsNvt68+bNNXXqVGVkZMjV1dXedqPmzZs7XD47YMAAffDBB3r11Vd16tQpffXVV9q4ceNtj+Obb76Rt7e3ff36ZT3XPfTQQ/ZL/aQ/3w9uvIzI1dVV/v7+On36tL1t2bJlevfdd5WYmKiUlBSlp6dnuQ8LKCoOHTqknTt3asWKFZIkNzc3PfPMM5o7d67Cw8Mdxt748zY4OFiSdPr0aZUvX16HDh3Siy++6DC+SZMmWV7HtWvXznJf1MCBA9WvXz/Fx8fLxcVFixcvztVZ4GXLluX4O4f052XFN74/BAYGytXVNct7wo2v//Xr1ysuLk4//vijkpOTlZ6erqtXr+ry5ctZ3vtQ8BCk4FReXl568MEHHdpuvORF+vPSuMGDB2v48OFZti9fvny+13OzG39xuv7LXHZtmZmZkv584ta6dev0zjvv6MEHH5Snp6e6d++ua9eu3dXagYIsN6/1KVOmaMaMGZo+fbr9noERI0bky2ulT58+eu2115SQkKBt27apYsWKatWq1W23q1ix4i3vV7g5WNlstmzbrr8/JCQkqFevXpowYYIiIiLk6+urpUuXaurUqeYHBRQCc+fOVXp6usPDJSzLkoeHh9577z35+vra22/1szW3vLy8srR16dJFHh4eWrFihdzd3ZWWlqbu3bvfdq7Q0NBb/o5g+vo/duyYOnfurCFDhmjSpEny8/PTt99+q/79++vatWsEqUKAIIUCr0GDBvrhhx9uG3Butn37dvXp08dhvX79+ne7vNvaunWr+vbtqyeffFLSn8Hw2LFj97wOoKDbunWrnnjiCftZqszMTB0+fFg1a9Z0GHfj/QXSn6/tKlWq2M9GXW+7ecyNf0n29/dX165dNX/+fCUkJNzxvRF5tW3bNlWoUEGvv/66ve3nn392Si1AfktPT9fChQs1depUtW/f3qGva9euWrJkiV544YVczVWtWjXt2rXL4ef8jfc93Yqbm5uioqI0f/58ubu7q0ePHk55Mt6ePXuUmZmpqVOn2s9affLJJ/e8DuQdQQoF3qhRo9SsWTMNHTpUAwYMkJeXl3744QetW7dO7733Xo7bLV++XI0aNVLLli21aNEi7dy587ZP5EpNTc3ymTBubm4qU6ZMnuuvUqWKPvvsM3Xp0kU2m01jxowx/osacD+oUqWKPv30U23btk2lS5dWfHy8Tp06lSVIHT9+XDExMRo8eLC+++47zZw5M8sZnK1bt+rtt99W165dtW7dOi1fvlyrV692GDNgwAB17txZGRkZioqKylWNp0+f1tWrVx3a/P39s/zVObeqVKmi48ePa+nSpWrcuLFWr15tv+QJKGpWrVqlP/74Q/3793c48yRJ3bp109y5c3MdpIYNG6aBAweqUaNGatGihZYtW6b9+/erUqVKudp+wIAB9j+ubN26NVfbnD17NsvvCKVKlVLx4sVztf3NHnzwQaWlpWnmzJnq0qWLtm7dqjlz5uRpLjgHT+1DgVenTh1t3rxZhw8fVqtWrVS/fn2NHTv2tp85MWHCBC1dulR16tTRwoULtWTJkiy/kN1szZo1Cg4Odlhatmx5R/XHx8erdOnSatGihbp06aKIiAg1aNDgjuYEiqLRo0erQYMGioiIUHh4uIKCgrL9IN8+ffroypUratKkiaKjo/XSSy9l+UDrl19+Wbt371b9+vX1xhtvKD4+XhEREQ5j2rVrp+DgYEVEROT6M2yqVauW5T1iz549eT7mxx9/XCNHjtTQoUNVr149bdu27baPYAYKq7lz56pdu3ZZQpT0Z5DavXu39u/fn6u5evXqpdjYWL3yyitq0KCBjh49qr59++Y61FSpUkUtWrRQ9erV1bRp01xtc/0948Zl5cqVudo2O3Xr1lV8fLwmT56sWrVqadGiRYqLi8vzfLj3bJaVzfMmgULOZrNpxYoV2f4SBqDwCg8PV7169W75uWthYWEaMWKERowYccu5UlJS9MADD2j+/Pl66qmn7m6hAO65xx57TEFBQfrHP/5x27GWZalKlSp68cUXFRMTcw+qQ1HEpX0AgPtKZmamfv/9d02dOlWlSpXS448/7uySABi6fPmy5syZo4iICLm6umrJkiVav369/fPibuXMmTNaunSpkpKSnHZ/JIoGghQA4L5y/PhxVaxYUeXKldOCBQvk5saPQqCwsdls+vLLLzVp0iRdvXpV1apV0z//+U+1a9futtsGBASoTJky+uCDD1S6dOl7UC2KKi7tAwAAAABDPGwCAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAAAAAAwRpAAAAADAEEEKAFBohYeHa8SIEc4uw66g1QMAyD8EKQDAfe3atWvOLgEAUAgRpAAAhVLfvn21efNmzZgxQzabTTabTYmJierfv78qVqwoT09PVatWTTNmzMiyXdeuXTVp0iSFhISoWrVqkqRt27apXr16Kl68uBo1aqSVK1fKZrNp79699m0PHDigyMhIlSxZUoGBgerdu7d+//33HOs5duzYvfp2AADuMTdnFwAAQF7MmDFDhw8fVq1atTRx4kRJUunSpVWuXDktX75c/v7+2rZtmwYNGqTg4GA9/fTT9m03bNggHx8frVu3TpKUnJysLl26qGPHjlq8eLF+/vnnLJfonT9/Xo8++qgGDBigadOm6cqVKxo1apSefvppbdy4Mdt6ypYte2++GQCAe44gBQAolHx9feXu7q4SJUooKCjI3j5hwgT71xUrVlRCQoI++eQThyDl5eWlv//973J3d5ckzZkzRzabTR9++KGKFy+umjVr6rffftPAgQPt27z33nuqX7++3nzzTXvbvHnzFBoaqsOHD6tq1arZ1gMAKJoIUgCAImXWrFmaN2+ejh8/ritXrujatWuqV6+ew5jatWvbQ5QkHTp0SHXq1FHx4sXtbU2aNHHYZt++fdq0aZNKliyZZZ+JiYmqWrXq3T0QAECBRpACABQZS5cu1SuvvKKpU6eqefPm8vb21pQpU7Rjxw6HcV5eXsZzp6SkqEuXLpo8eXKWvuDg4DzXDAAonAhSAIBCy93dXRkZGfb1rVu3qkWLFnrxxRftbYmJibedp1q1avr444+VmpoqDw8PSdKuXbscxjRo0ED//Oc/FRYWJje37H983lwPAKDo4ql9AIBCKywsTDt27NCxY8f0+++/q0qVKtq9e7fWrl2rw4cPa8yYMVkCUXaeffZZZWZmatCgQTp48KDWrl2rd955R5Jks9kkSdHR0Tp37px69uypXbt2KTExUWvXrtXzzz9vD08315OZmZl/Bw8AcCqCFACg0HrllVfk6uqqmjVrqmzZsoqIiNBTTz2lZ555Rk2bNtXZs2cdzk7lxMfHR1988YX27t2revXq6fXXX9fYsWMlyX7fVEhIiLZu3aqMjAy1b99etWvX1ogRI1SqVCm5uLhkW8/x48fz7+ABAE5lsyzLcnYRAAAUNIsWLdLzzz+vCxcuyNPT09nlAAAKGO6RAgBA0sKFC1WpUiU98MAD2rdvn/0zoghRAIDsEKQAAJCUlJSksWPHKikpScHBwfrLX/6iSZMmObssAEABxaV9AAAAAGCIh00AAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAYIkgBAAAAgCGCFAAAAAAY+v9u0lD0MNQ0/wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_df = df['target'].value_counts().reset_index()\n",
    "target_df.columns = ['target', 'Count']\n",
    "plot_bar_graph(data=target_df, x_col=\"target\", y_col=\"Count\", title=\"Ticket Type Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHF2CtjIQ-dB",
    "outputId": "03038a95-fb47-4f1f-ca4b-0d81cfc333c5"
   },
   "source": [
    "- Among the 450 emails, 199 fall into the 'Help Email' category.\n",
    "- A total of 133 emails out of the 450 are categorized as 'Happy Email.'\n",
    "- Furthermore, 118 out of the 450 emails are classified as 'Angry Email.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a spacy model for tokenizing a sentence\n",
    "\n",
    "**Model: en_core_web_lg**\n",
    "\n",
    "The \"en_core_web_lg\" model is a pre-trained language model provided by spaCy. It is designed for various natural language processing (NLP) tasks in English.\n",
    "\n",
    "**Key Features:**\n",
    "- **Word Vectors**: This model is equipped with word vectors trained on a large corpus of text data. These word vectors enable it to understand the context and similarity between words, making it suitable for tasks like word embeddings, text similarity analysis and sentiment analysis.\n",
    "\n",
    "**Training Data:**\n",
    "- The \"en_core_web_lg\" model was trained on a diverse range of English text from the web, including news articles, books, and websites. It has been fine-tuned to capture a broad vocabulary and linguistic patterns.\n",
    "\n",
    "This model serves as a versatile tool for NLP tasks such as text classification, named entity recognition, part-of-speech tagging, and more. It's a valuable resource for understanding and processing English text data efficiently.\n",
    "\n",
    "**Utilizing the Model for Sentiment Analysis**\n",
    "\n",
    "In our case, we leverage the capabilities of the \"en_core_web_lg\" model for conducting sentiment analysis through text classification.\n",
    "\n",
    "**Categorizing Customer Sentiments**\n",
    "\n",
    "Our primary objective is to categorize customers based on the sentiments expressed in their emails, particularly focusing on their feedback regarding our products. We aim to classify customers as either happy, expressing dissatisfaction, or seeking assistance based on the content of their emails.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yH0c4AxORAkG"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to remove commonly used words in a text\n",
    "\n",
    "<b>Stopwords</b> are common words in natural language that are often filtered out when analyzing text data because they typically don't carry significant meaning on their own. They are frequently used in language but may not provide valuable information for tasks like text analysis and natural language processing. \n",
    "\n",
    "Here are two to three examples of common stopwords:\n",
    "\n",
    "1. English Stopwords:\n",
    "   - Articles: \"a,\" \"an,\" \"the\"\n",
    "   - Pronouns: \"I,\" \"you,\" \"he,\" \"she,\" \"it,\" \"we,\" \"they\"\n",
    "   - Prepositions: \"in,\" \"on,\" \"at,\" \"with,\" \"by,\" \"for,\" \"of,\" \"to,\" \"from\"\n",
    "   - Conjunctions: \"and,\" \"but,\" \"or,\" \"so,\" \"because\"\n",
    "\n",
    "These stopwords are often removed from text data during text preprocessing to focus on more meaningful words and improve the efficiency and effectiveness of natural language processing tasks such as text classification, sentiment analysis, and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hYOOhVE2R4E6"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Remove stopwords from the input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text from which stopwords will be removed.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text with stopwords removed.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    cleaned_text = ' '.join(token.text for token in doc if not token.is_stop)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "This function performs essential text cleaning steps, making the input text suitable for analysis and natural language processing. The process includes:\n",
    "\n",
    "- **Tokenization:** Breaking text into words or tokens.\n",
    "- **Lowercasing:** Converting tokens to lowercase.\n",
    "- **Punctuation Removal:** Eliminating punctuation marks.\n",
    "- **Special Character Removal:** Removing non-alphanumeric characters.\n",
    "- **Whitespace Cleanup:** Ensuring consistent and clean spaces.\n",
    "\n",
    "The result is a cleaned and preprocessed text, ready for doing Named Entity Recognition(NER).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wmFVmYmlR9_B"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess the input text.\n",
    "\n",
    "    This function tokenizes the input text, converts tokens to lowercase,\n",
    "    removes punctuation, and ensures that the text only contains letters,\n",
    "    digits, and whitespace.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and preprocessed text.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    cleaned_text = ' '.join(token.text.lower() for token in doc if not token.is_punct)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', re.sub(r'[^a-zA-Z0-9\\s]', '', cleaned_text)).strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying text cleaning operation in our email description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LA1rzFHHR_Rf"
   },
   "outputs": [],
   "source": [
    "df['Ticket Description'] = df['Ticket Description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop words from our email description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ggEyUVrESYp_"
   },
   "outputs": [],
   "source": [
    "df['Ticket Description'] = df['Ticket Description'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Encoding in Sentiment Analysis**\n",
    "\n",
    "Label encoding is the process of converting categorical labels, like class names, into numerical values. In classification problems, we use label encoding to make it easier for machine learning models to process target labels. This conversion is particularly crucial for tasks like sentiment analysis of emails.\n",
    "\n",
    "In our case, we have three classes: 'Angry Email,' 'Happy Email,' and 'Help Email.' Label encoding assigns numerical values, typically starting from 0, to these categories. For example:\n",
    "\n",
    "- 'Angry Email' might be encoded as 0.\n",
    "- 'Happy Email' could be encoded as 1.\n",
    "- 'Help Email' may receive an encoding of 2.\n",
    "\n",
    "This encoding simplifies the model's understanding of the categories. In our context, 'Angry Email' represents dissatisfaction or technical issues, 'Happy Email' indicates positive feedback on new features, and 'Help Email' signifies inquiries or requests for assistance. Label encoding streamlines the sentiment classification task, enabling efficient analysis of customer emails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "j-G2xB3OT_KF"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting the random seed using `np.random.seed(42)` ensures consistent random processes with NumPy.\n",
    "- It's crucial for reproducibility in scenarios like machine learning experiments.\n",
    "- The seed value, 42, guarantees the same random results in each code run.\n",
    "- This consistency aids debugging and result comparison in different program runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5v0Bvt2wVFDQ"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting our dataset as train & test\n",
    "\n",
    "- `train_test_split` is a function used to split a dataset into two parts: a training set and a testing (or validation) set.\n",
    "- It's essential for assessing a machine learning model's performance. The training set is used to train the model, and the testing set is used to evaluate its performance on unseen data.\n",
    "- The `test_size` parameter specifies the proportion of data to include in the testing set. In this case, it's set to 0.2, meaning 20% of the data will be used for testing.\n",
    "- `random_state` is used to initialize the random number generator. Setting it to a specific value (e.g., 42) ensures that the split is reproducible across different runs of the code.\n",
    "- `stratify` is used for stratified sampling. When you set it to a variable (in this case, `df['target']`), it ensures that the class distribution in the training and testing sets is similar to the original dataset. This is particularly useful for imbalanced datasets to maintain representative class proportions.\n",
    "\n",
    "Output:\n",
    "- Training set (`x_train` and `y_train`) has a shape of (number of samples, number of features).\n",
    "- Testing set (`x_test` and `y_test`) also has its shape displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFWYB0TFVFHU",
    "outputId": "b0d8fc74-7f9b-42bc-8ba8-54210509e65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360,)\n",
      "(360,)\n",
      "(90,)\n",
      "(90,)\n"
     ]
    }
   ],
   "source": [
    "X = df['Ticket Description']\n",
    "y = df['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = df['target'])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF Vectorizer (Term Frequency-Inverse Document Frequency Vectorizer)**\n",
    "\n",
    "- **Role in Text Classification:**\n",
    "  - TF-IDF Vectorizer is a crucial tool in text classification and natural language processing tasks.\n",
    "  - Its primary role is to convert a collection of text documents into numerical feature vectors.\n",
    "  - These feature vectors represent the importance of each word or term within the documents.\n",
    "  - TF-IDF helps address the issue of textual data's high dimensionality by transforming it into a more manageable numerical format.\n",
    "  - It assigns numerical weights to terms based on their frequency within a document and their rarity across all documents in the corpus.\n",
    "  - TF-IDF is essential for text classification because it captures the significance of words in distinguishing one category from another.\n",
    "  - Words that are frequent in one category but rare in others are given higher weights, aiding the classifier in making accurate predictions.\n",
    "  - By converting text data into a numerical format, TF-IDF enables the application of machine learning algorithms for classification tasks.\n",
    "\n",
    "- **How It Works:**\n",
    "  - TF-IDF stands for Term Frequency-Inverse Document Frequency.\n",
    "  - It calculates two main components for each term in a document:\n",
    "    - Term Frequency (TF): Measures how often a term appears in a document. It's calculated as the ratio of the term's frequency to the total number of terms in the document.\n",
    "    - Inverse Document Frequency (IDF): Measures the rarity of a term across all documents in the corpus. It's calculated as the logarithm of the total number of documents divided by the number of documents containing the term.\n",
    "  - The TF-IDF score for a term in a document is obtained by multiplying its TF and IDF values.\n",
    "  - Terms that are frequent within a specific document but rare across the entire corpus receive high TF-IDF scores.\n",
    "  - The resulting TF-IDF vectors represent documents as numerical feature vectors, where each dimension corresponds to a unique term.\n",
    "  - These vectors are used as input for machine learning models, enabling text classification based on the importance of terms within documents.\n",
    "\n",
    "TF-IDF Vectorizer is a powerful tool for text classification as it captures the essence of terms in documents, making it easier for machine learning models to learn and classify text data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF (Term Frequency):\n",
    "\n",
    "<li>TF measures how often a word appears in a document.</li>\n",
    "\n",
    "**Formula:**\n",
    "<code>\n",
    "TF(t, d) = (Number of times term t appears in document d) / (Total terms in document d)\n",
    "</code>\n",
    "\n",
    "#### IDF (Inverse Document Frequency):\n",
    "\n",
    "<li>IDF measures the importance of a word across a collection of documents.</li>\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "<code>\n",
    "IDF(t, D) = log(Total documents in corpus |D| / Documents containing term t)\n",
    "</code>\n",
    "\n",
    "#### TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "\n",
    "<li>TF-IDF combines TF and IDF to compute a weighted score for each word.</li>\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "<code>\n",
    "TF-IDF(t, d, D) = TF(t, d) Ã— IDF(t, D)\n",
    "</code>\n",
    "\n",
    "<li>These formulas are essential for text analysis, helping identify word importance in documents, making them valuable for text classification and information retrieval tasks.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RqtLq4StSsPr"
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJBQPSaOWbzg"
   },
   "source": [
    "**Applying TF-IDF Vectorization: Training vs. Testing Datasets**\n",
    "\n",
    "- **Training Dataset (x_train):**\n",
    "  - When applying TF-IDF vectorization to the training dataset (x_train), we use the `fit_transform` operation.\n",
    "  - The `fit_transform` operation serves two primary purposes:\n",
    "    1. **Fit**: It analyzes the training data to identify all unique terms (words) present in the documents. This step builds the vocabulary.\n",
    "    2. **Transform**: It transforms the documents in the training dataset into TF-IDF feature vectors based on the learned vocabulary.\n",
    "  - This is a critical step because it ensures that the TF-IDF vectorizer calculates IDF scores and scales the term frequencies according to the entire training corpus.\n",
    "\n",
    "- **Testing Dataset (x_test):**\n",
    "  - When applying TF-IDF vectorization to the testing dataset (x_test), we use the `transform` operation.\n",
    "  - The `transform` operation only performs the second part of TF-IDF vectorization: transforming the documents into feature vectors.\n",
    "  - We do not perform the \"fit\" part because the vocabulary (unique terms) has already been learned from the training dataset.\n",
    "  - Using the same vocabulary ensures consistency in how terms are represented between the training and testing datasets.\n",
    "  - This is essential to maintain the integrity of the feature space, as the model must make predictions on data with the same term-to-vector mapping.\n",
    "\n",
    "In summary, we use `fit_transform` on the training dataset to build the vocabulary and transform the training documents into TF-IDF vectors. For the testing dataset, we use `transform` to apply the same transformation based on the learned vocabulary from the training data. This approach ensures that both datasets are represented consistently in the same feature space, facilitating accurate model predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SrMQeeNWa_e",
    "outputId": "be14564b-0b6c-487d-8644-b6c34aca31eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 2479)\n"
     ]
    }
   ],
   "source": [
    "x_train_tf_idf = tf_idf.fit_transform(x_train)\n",
    "print(x_train_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-O7CPgUEWpgr",
    "outputId": "544b03dc-afac-4c41-ca87-996792f93f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 2479)\n"
     ]
    }
   ],
   "source": [
    "x_test_tf_idf = tf_idf.transform(x_test)\n",
    "print(x_test_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes for Email Sentiment Classification About Certain Products\n",
    "\n",
    "**Multinomial Naive Bayes (MultinomialNB)** is a probabilistic machine learning model commonly used for text classification tasks, particularly when dealing with discrete features, such as word counts. It's based on the Naive Bayes algorithm, which is a probabilistic classification method relying on Bayes' theorem. \n",
    "\n",
    "### How Multinomial Naive Bayes Works:\n",
    "\n",
    "**Data Preparation:** The model requires a dataset with features (in this case, TF-IDF values of words) and corresponding target labels (sentiment categories: 'Angry Email,' 'Happy Email,' 'Help Email').\n",
    "\n",
    "**Training:** During the training phase, the model learns the statistical probabilities of different features (words) occurring in each class (sentiment category). Specifically, it calculates the probabilities of observing each feature (word) given a class (sentiment category).\n",
    "\n",
    "**Prediction:** In the prediction phase, the model uses these probabilities to classify new, unseen data. For a given input (e.g., a new email represented as TF-IDF values), the model calculates the probability of it belonging to each class based on the features it contains (words). It assigns the class with the highest probability as the predicted class for the input.\n",
    "\n",
    "### Mathematical Formula:\n",
    "\n",
    "The core of Naive Bayes algorithms, including Multinomial Naive Bayes, is Bayes' theorem, which relates the conditional probability of an event given prior knowledge to the unconditional probability of that event. In the case of Multinomial Naive Bayes, the formula for classifying an input into class C is:\n",
    "\n",
    "**P(Câˆ£x) = P(x) * P(C) / P(xâˆ£C)**\n",
    "\n",
    "Where:\n",
    "\n",
    "- **P(Câˆ£x)** is the posterior probability of class C given input x.\n",
    "- **P(C)** is the prior probability of class C.\n",
    "- **P(xâˆ£C)** is the likelihood of observing input x given class C.\n",
    "- **P(x)** is the marginal likelihood, representing the probability of observing input x across all classes.\n",
    "\n",
    "In practice, to calculate **P(xâˆ£C)** for text classification, the Multinomial Naive Bayes classifier makes a crucial assumption of conditional independence between features (words). This means it assumes that the presence of one word in the text does not affect the presence of other words. As a result, the formula is simplified to:\n",
    "\n",
    "**P(xâˆ£C) = P(wordâ‚âˆ£C) * P(wordâ‚‚âˆ£C) * â€¦ * P(wordâ‚™âˆ£C)**\n",
    "\n",
    "Where **wordâ‚, wordâ‚‚, â€¦, wordâ‚™** are the words in the input x.\n",
    "\n",
    "The model calculates these probabilities using the training data and applies Bayes' theorem to classify new data.\n",
    "\n",
    "In summary, Multinomial Naive Bayes is a probabilistic model that works well for text classification tasks by considering the probabilities of words occurring in each class and making predictions based on these probabilities. It's especially useful for sentiment analysis where the goal is to categorize text data into predefined sentiment categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase\n",
    "\n",
    "**During the training phase,** the Multinomial Naive Bayes classifier learns from the training data. It achieves this by calculating probabilities of words occurring in each class (sentiment category) based on the TF-IDF values.\n",
    "\n",
    "**Model Building:** The classifier builds a model that can distinguish between 'Angry Email,' 'Happy Email,' and 'Help Email' based on these calculated probabilities.\n",
    "\n",
    "### Prediction Phase\n",
    "\n",
    "**Once the model is trained,** we can use it to predict the sentiment categories of new email messages. These messages are represented as TF-IDF values.\n",
    "\n",
    "**Test Dataset:** In this case, we have the test dataset (x_test_tf_idf) containing a set of email messages that the model has never seen before.\n",
    "\n",
    "### Making Predictions\n",
    "\n",
    "**To make predictions,** we call the predict method on the trained classifier (clf).\n",
    "\n",
    "**Input:** We pass in the TF-IDF values of the test emails (x_test_tf_idf).\n",
    "\n",
    "**Classifier Knowledge:** The classifier applies its learned knowledge to calculate the likelihood of each email belonging to each sentiment category ('Angry Email,' 'Happy Email,' 'Help Email').\n",
    "\n",
    "### Output\n",
    "\n",
    "**The output** of the prediction process is a set of predicted sentiment categories for each email in the test dataset.\n",
    "\n",
    "**Result (y_pred):** These predicted categories (y_pred) represent the model's best guess at the sentiment expressed in each email.\n",
    "\n",
    "### Summary\n",
    "\n",
    "**In summary,** once we train a Multinomial Naive Bayes classifier, we can utilize it to classify new email messages into sentiment categories. This automated process helps us categorize and analyze customer feedback effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "crjeYcOaW-hJ",
    "outputId": "d3619dd2-0b9d-4a85-bfae-7eee9487d769"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_tf_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xh7vPf4DXc2_"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Metrics\n",
    "\n",
    "- In our problem of classifying customer feedback emails into sentiment categories ('Angry Email,' 'Happy Email,' 'Help Email'), we use the following performance metrics:\n",
    "\n",
    "- <b>Accuracy Score:</b> Measures overall correctness in classifying sentiments.\n",
    "\n",
    "- <b>Precision:</b> Focuses on accurately identifying each sentiment category, vital for avoiding misclassification.\n",
    "\n",
    "- <b>Recall (Sensitivity):</b> Ensures we capture as many instances of each sentiment category as possible, reducing the risk of missing critical feedback.\n",
    "\n",
    "- <b>F1 Score:</b> Balances precision and recall, ideal for finding a compromise between accuracy and coverage.\n",
    "\n",
    "- <b>Classification Report:</b> Provides a detailed breakdown of metrics for each sentiment category, helping us identify specific strengths and weaknesses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liWSYkEyXjQd",
    "outputId": "8e6d50aa-cbd6-4894-f2e0-75c7bbaab1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       1.00      1.00      1.00        26\n",
      "           2       1.00      1.00      1.00        40\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation\n",
    "\n",
    "**Accuracy:** An accuracy of 1.00 indicates that the model correctly classified all emails in the test dataset. This may suggest that the model performed exceptionally well.\n",
    "\n",
    "**Precision:** Precision measures the accuracy of positive predictions. The precision of 1.00 for all classes implies that there were no false positives in any sentiment category. This is an impressive result.\n",
    "\n",
    "**Recall:** Recall, or sensitivity, measures the model's ability to capture all positive instances. Again, a score of 1.00 for all categories suggests that the model didn't miss any positive instances.\n",
    "\n",
    "**F1-Score:** The F1-score is the harmonic mean of precision and recall. Its perfect score of 1.00 for all classes indicates a well-balanced performance between precision and recall.\n",
    "\n",
    "## Justification of High Accuracy\n",
    "\n",
    "The high accuracy observed can be attributed to a few factors:\n",
    "\n",
    "1. **Biased Data Generation:** If the model was trained or fine-tuned using data generated by ChatGPT, it might have learned to mimic the patterns and biases present in that data. This could lead to high accuracy when tested on similar data generated by the same model.\n",
    "\n",
    "2. **Specific Prompts:** If the email generation process relies heavily on specific prompts that control the content and sentiment, the model may excel at producing the desired sentiment categories. However, this may not reflect the real-world scenario of customer feedback, where the content is more diverse and unstructured.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "While the model's high accuracy is impressive within the context of the data it was tested on, it's essential to recognize that real-world customer feedback is far more complex and varied. Achieving such high accuracy in a controlled setting does not guarantee similar performance in a genuine customer feedback scenario. Therefore, further evaluation and testing on diverse, real-world data are necessary to assess the model's practical utility and robustness in a more realistic context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving label encoder and classifier model for model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-219/Desktop/product_and_sentiment_classification_poc/models/classifier_model.pkl\n",
      "/home/fm-pc-lt-219/Desktop/product_and_sentiment_classification_poc/models/label_encoder.pkl\n",
      "/home/fm-pc-lt-219/Desktop/product_and_sentiment_classification_poc/models/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "classifier_filename = 'classifier_model.pkl'\n",
    "label_encoder_filename = 'label_encoder.pkl'\n",
    "tfidf_vectorizer_filename = \"tfidf_vectorizer.pkl\"\n",
    "\n",
    "path_to_classifier = os.path.join(os.path.dirname(os.getcwd()), 'models', classifier_filename)\n",
    "path_to_label_encoder = os.path.join(os.path.dirname(os.getcwd()), 'models', label_encoder_filename)\n",
    "path_to_tfidf_vectorizer = os.path.join(os.path.dirname(os.getcwd()), 'models', tfidf_vectorizer_filename)\n",
    "print(path_to_classifier)\n",
    "print(path_to_label_encoder)\n",
    "print(path_to_tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_classifier, 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_label_encoder, 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_tfidf_vectorizer, 'wb') as file:\n",
    "    pickle.dump(tf_idf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
